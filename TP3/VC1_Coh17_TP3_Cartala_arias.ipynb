{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visión por Computadora 1 - Cohorte 17\n",
    "## Trabajo Práctico 3\n",
    "## Paola Cartala - Florentino Arias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Detección del logo en cada imagen sin falsos positivos.\n",
    "Vamos a utilizar cv2.matchTemplate() para implementar el método de template matching. Filtramos los resultados para evitar falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el template\n",
    "template = cv2.imread('template.png', cv2.IMREAD_GRAYSCALE)\n",
    "template_h, template_w = template.shape\n",
    "\n",
    "# Lista de imágenes a procesar\n",
    "image_paths = ['images/image1.png', 'images/image2.png', 'images/image3.png']\n",
    "\n",
    "for path in image_paths:\n",
    "    # Leer la imagen\n",
    "    image = cv2.imread(path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Aplicar template matching\n",
    "    result = cv2.matchTemplate(gray_image, template, cv2.TM_CCOEFF_NORMED) # Utilizamos correlación normalizada (TM_CCOEFF_NORMED) para medir la similitud.\n",
    "    threshold = 0.8  # Ajustar el umbral para evitar falsos positivos\n",
    "    locations = np.where(result >= threshold)\n",
    "    \n",
    "    # Dibujar los bounding boxes para cada coincidencia\n",
    "    for pt in zip(*locations[::-1]):\n",
    "        cv2.rectangle(image, pt, (pt[0] + template_w, pt[1] + template_h), (0, 255, 0), 2)\n",
    "        confidence = result[pt[1], pt[0]]\n",
    "        cv2.putText(image, f'{confidence:.2f}', (pt[0], pt[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Detección en {path}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Algoritmo para múltiples detecciones en 'coca_multi.png'\n",
    "Para múltiples instancias del logotipo en la imagen coca_multi.png tenemos que ajustar la lógica para permitir múltiples detecciones.\n",
    "\n",
    "Se dibujan todos los bounding boxes que cumplen con el umbral definido (threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar la imagen coca_multi.png\n",
    "multi_image_path = 'images/coca_multi.png'\n",
    "multi_image = cv2.imread(multi_image_path)\n",
    "gray_multi_image = cv2.cvtColor(multi_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar template matching\n",
    "result_multi = cv2.matchTemplate(gray_multi_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "threshold_multi = 0.8\n",
    "locations_multi = np.where(result_multi >= threshold_multi)\n",
    "\n",
    "# Dibujar bounding boxes para cada coincidencia\n",
    "for pt in zip(*locations_multi[::-1]):\n",
    "    cv2.rectangle(multi_image, pt, (pt[0] + template_w, pt[1] + template_h), (0, 255, 0), 2)\n",
    "    confidence = result_multi[pt[1], pt[0]]\n",
    "    cv2.putText(multi_image, f'{confidence:.2f}', (pt[0], pt[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "plt.imshow(cv2.cvtColor(multi_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Múltiples detecciones en coca_multi.png')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Generalización del algoritmo para todas las imágenes.\n",
    "Vamos a generalizar el algoritmo para todas las imágenes de la carpeta y usaremos el método de supresión de no máximos (NMS) para evitar solapamientos innecesarios en las detecciones.\n",
    "\n",
    "Usamos glob para iterar sobre todas las imágenes en la carpeta 'images'.\n",
    "\n",
    "Implementamos la función non_max_suppression() para evitar múltiples detecciones del mismo logo muy cercanas entre sí.\n",
    "\n",
    "Dibujamos los bounding boxes solo para las detecciones que quedan después de aplicar NMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Función para aplicar NMS\n",
    "def non_max_suppression(boxes, scores, threshold=0.5):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        overlap = (w * h) / areas[order[1:]]\n",
    "\n",
    "        order = order[np.where(overlap <= threshold)[0] + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "# Generalizar para todas las imágenes\n",
    "all_images_paths = glob.glob('images/*.png')\n",
    "\n",
    "for path in all_images_paths:\n",
    "    # Leer la imagen\n",
    "    image = cv2.imread(path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Aplicar template matching\n",
    "    result = cv2.matchTemplate(gray_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.8\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # Guardar las coordenadas de las detecciones y sus puntuaciones\n",
    "    boxes = []\n",
    "    scores = []\n",
    "\n",
    "    for pt in zip(*locations[::-1]):\n",
    "        x1, y1 = pt\n",
    "        x2, y2 = x1 + template_w, y1 + template_h\n",
    "        confidence = result[pt[1], pt[0]]\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        scores.append(confidence)\n",
    "\n",
    "    # Aplicar NMS para eliminar solapamientos\n",
    "    keep_indices = non_max_suppression(boxes, scores, threshold=0.5)\n",
    "\n",
    "    # Dibujar los bounding boxes finales\n",
    "    for idx in keep_indices:\n",
    "        x1, y1, x2, y2 = boxes[idx]\n",
    "        confidence = scores[idx]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Mostrar el resultado\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Detección generalizada en {path}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Puntos extra. Aplicar unsharp masking para expandir la zona de enfoque y devolver.\n",
    "Vamos a aplicar unsharp masking para mejorar la nitidez de las imágenes y expandir la zona de enfoque. Esto resalta los detalles al aumentar el contraste de los bordes haciendo así que el logotipo sea más visible antes de la detección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.5, threshold=0):\n",
    "    # Aplicar suavizado Gaussian a la imagen\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "\n",
    "    # Calcular la máscara\n",
    "    mask = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)\n",
    "\n",
    "    # Aplicar umbral para mejorar detalles\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.abs(image - blurred) < threshold\n",
    "        np.copyto(mask, image, where=low_contrast_mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Lista de imágenes a procesar\n",
    "all_images_paths = glob.glob('images/*.png')\n",
    "\n",
    "# Cargar el template\n",
    "template = cv2.imread('template.png', cv2.IMREAD_GRAYSCALE)\n",
    "template_h, template_w = template.shape\n",
    "\n",
    "for path in all_images_paths:\n",
    "    # Leer la imagen\n",
    "    image = cv2.imread(path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Aplicar Unsharp Masking\n",
    "    sharpened_image = unsharp_mask(gray_image, kernel_size=(5, 5), sigma=1.0, amount=1.5, threshold=10)\n",
    "\n",
    "    # Aplicar template matching sobre la imagen mejorada\n",
    "    result = cv2.matchTemplate(sharpened_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.8\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # Dibujar los bounding boxes para cada coincidencia\n",
    "    for pt in zip(*locations[::-1]):\n",
    "        cv2.rectangle(image, pt, (pt[0] + template_w, pt[1] + template_h), (0, 255, 0), 2)\n",
    "        confidence = result[pt[1], pt[0]]\n",
    "        cv2.putText(image, f'{confidence:.2f}', (pt[0], pt[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Mostrar el resultado\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Detección con Unsharp Masking en {path}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hicimos fue aplicar unsharp_mask a la imagen en escala de grises para resaltar los bordes y después realizamos template matching con la imagen mejorada para detectar el logotipo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
